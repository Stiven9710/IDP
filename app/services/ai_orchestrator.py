"""
Orquestador de servicios de IA para el procesamiento de documentos
"""

import asyncio
import base64
import logging
import time
from datetime import datetime
from typing import List, Dict, Any, Optional
from dataclasses import dataclass

from app.core.config import settings
from app.models.request import FieldDefinition
from app.models.response import ExtractionField, ProcessingMode
from app.utils.azure_clients import AzureOpenAIClient, CustomDocumentIntelligenceClient

# Configurar logging
logger = logging.getLogger(__name__)


@dataclass
class ExtractionResult:
    """Resultado de la extracci√≥n de datos"""
    extraction_data: List[ExtractionField]
    pages_processed: int
    review_flags: List[str]
    processing_time_ms: int
    strategy_used: str


class AIOrchestrator:
    """Servicio orquestador de IA para procesamiento de documentos"""
    
    def __init__(self):
        """Inicializar el orquestador de IA"""
        self.openai_client = AzureOpenAIClient()
        self.doc_intelligence_client = CustomDocumentIntelligenceClient()
        
        logger.info("ü§ñ AIOrchestrator inicializado correctamente")
    
    async def process_document(
        self,
        document_content: bytes,
        fields: List[FieldDefinition],
        prompt_general: str,
        processing_mode: str
    ) -> ExtractionResult:
        """
        Procesar documento con la estrategia de IA especificada
        
        Args:
            document_content: Contenido del documento en bytes
            fields: Lista de campos a extraer
            prompt_general: Prompt general para la extracci√≥n
            processing_mode: Modo de procesamiento a utilizar
            
        Returns:
            Resultado de la extracci√≥n con los datos procesados
        """
        start_time = time.time()
        logger.info(f"ü§ñ Iniciando procesamiento de IA con modo: {processing_mode}")
        logger.info(f"üìù N√∫mero de campos a extraer: {len(fields)}")
        
        try:
            # Determinar estrategia de procesamiento
            if processing_mode == ProcessingMode.DUAL_SERVICE:
                logger.info("üîÑ Procesando con estrategia DUAL SERVICE")
                result = await self._process_dual_service(
                    document_content, fields, prompt_general
                )
            elif processing_mode == ProcessingMode.GPT_VISION_ONLY:
                logger.info("üëÅÔ∏è Procesando con estrategia GPT VISION ONLY")
                result = await self._process_gpt_vision_only(
                    document_content, fields, prompt_general
                )
            elif processing_mode == ProcessingMode.HYBRID_CONSENSUS:
                logger.info("üéØ Procesando con estrategia HYBRID CONSENSUS")
                result = await self._process_hybrid_consensus(
                    document_content, fields, prompt_general
                )
            else:
                raise ValueError(f"Modo de procesamiento no soportado: {processing_mode}")
            
            # Calcular tiempo total
            processing_time_ms = int((time.time() - start_time) * 1000)
            result.processing_time_ms = processing_time_ms
            
            logger.info(f"‚úÖ Procesamiento de IA completado en {processing_time_ms}ms")
            logger.info(f"üìä Campos extra√≠dos: {len(result.extraction_data)}")
            logger.info(f"üîç Banderas de revisi√≥n: {len(result.review_flags)}")
            
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error en el procesamiento de IA: {str(e)}")
            raise
    
    async def _process_dual_service(
        self,
        document_content: bytes,
        fields: List[FieldDefinition],
        prompt_general: str
    ) -> ExtractionResult:
        """Procesar documento usando ambos servicios en paralelo"""
        logger.info("üîÑ Iniciando procesamiento DUAL SERVICE")
        
        # Ejecutar ambos servicios en paralelo
        openai_task = self._process_with_openai(document_content, fields, prompt_general)
        doc_intelligence_task = self._process_with_document_intelligence(
            document_content, fields, prompt_general
        )
        
        openai_result, doc_intelligence_result = await asyncio.gather(
            openai_task, doc_intelligence_task, return_exceptions=True
        )
        
        # Analizar resultados y crear consenso
        extraction_data = []
        review_flags = []
        
        for field in fields:
            field_name = field.name
            openai_value = None
            doc_intelligence_value = None
            
            # Obtener valores de cada servicio
            if not isinstance(openai_result, Exception):
                openai_value = self._get_field_value(openai_result, field_name)
            
            if not isinstance(doc_intelligence_result, Exception):
                doc_intelligence_value = self._get_field_value(doc_intelligence_result, field_name)
            
            # Crear campo con consenso
            field_result = self._create_consensus_field(
                field_name, openai_value, doc_intelligence_value, field
            )
            extraction_data.append(field_result)
            
            # Marcar para revisi√≥n si hay discrepancias
            if (openai_value is not None and doc_intelligence_value is not None and 
                openai_value != doc_intelligence_value):
                review_flags.append(f"Discrepancia en campo '{field_name}' entre servicios")
        
        return ExtractionResult(
            extraction_data=extraction_data,
            pages_processed=1,  # Por defecto, ajustar seg√∫n el documento
            review_flags=review_flags,
            processing_time_ms=0,  # Se calcula despu√©s
            strategy_used="dual_service"
        )
    
    async def _process_gpt_vision_only(
        self,
        document_content: bytes,
        fields: List[FieldDefinition],
        prompt_general: str
    ) -> ExtractionResult:
        """Procesar documento usando solo Azure OpenAI GPT-4 Vision con estrategia cascada"""
        logger.info("üëÅÔ∏è Iniciando procesamiento GPT VISION ONLY con estrategia cascada")
        logger.info(f"   üìä Tama√±o del documento: {len(document_content)} bytes")
        logger.info(f"   üîç Primeros bytes: {document_content[:10]}")
        
        try:
            # Usar procesamiento cascada para mantener contexto entre p√°ginas
            logger.info("   üîÑ Llamando a _process_with_openai_cascade...")
            result = await self._process_with_openai_cascade(document_content, fields, prompt_general)
            logger.info("   ‚úÖ _process_with_openai_cascade completado exitosamente")
            
            extraction_data = []
            for field in fields:
                field_value = self._get_field_value(result, field.name)
                field_result = ExtractionField(
                    name=field.name,
                    value=field_value,
                    confidence=0.9,  # Alta confianza para GPT-4 Vision
                    review_required=False,
                    source_strategy="gpt_vision_only_cascade",
                    extraction_time_ms=0
                )
                extraction_data.append(field_result)
            
            return ExtractionResult(
                extraction_data=extraction_data,
                pages_processed=result.get('pages_processed', 1),
                review_flags=[],
                processing_time_ms=0,
                strategy_used="gpt_vision_only_cascade"
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error en procesamiento GPT Vision Cascada: {str(e)}")
            raise
    
    async def _process_hybrid_consensus(
        self,
        document_content: bytes,
        fields: List[FieldDefinition],
        prompt_general: str
    ) -> ExtractionResult:
        """Procesar documento usando consenso h√≠brido"""
        logger.info("üéØ Iniciando procesamiento HYBRID CONSENSUS")
        
        # Obtener resultados de ambos servicios
        openai_result = await self._process_with_openai(document_content, fields, prompt_general)
        doc_intelligence_result = await self._process_with_document_intelligence(
            document_content, fields, prompt_general
        )
        
        extraction_data = []
        review_flags = []
        
        for field in fields:
            field_name = field.name
            openai_value = self._get_field_value(openai_result, field_name)
            doc_intelligence_value = self._get_field_value(doc_intelligence_result, field_name)
            
            # L√≥gica de consenso h√≠brido
            if openai_value is not None and doc_intelligence_value is not None:
                if openai_value == doc_intelligence_value:
                    # Consenso perfecto
                    final_value = openai_value
                    confidence = 0.95
                    review_required = False
                else:
                    # Discrepancia - usar OpenAI como autoridad
                    final_value = openai_value
                    confidence = 0.8
                    review_required = True
                    review_flags.append(f"Discrepancia en '{field_name}': OpenAI='{openai_value}', DI='{doc_intelligence_value}'")
            elif openai_value is not None:
                # Solo OpenAI tiene valor
                final_value = openai_value
                confidence = 0.85
                review_required = False
            elif doc_intelligence_value is not None:
                # Solo Document Intelligence tiene valor
                final_value = doc_intelligence_value
                confidence = 0.75
                review_required = True
                review_flags.append(f"Campo '{field_name}' solo extra√≠do por Document Intelligence")
            else:
                # Ning√∫n servicio extrajo valor
                final_value = None
                confidence = 0.0
                review_required = True
                review_flags.append(f"Campo '{field_name}' no extra√≠do por ning√∫n servicio")
            
            field_result = ExtractionField(
                name=field_name,
                value=final_value,
                confidence=confidence,
                review_required=review_required,
                source_strategy="hybrid_consensus",
                extraction_time_ms=0
            )
            extraction_data.append(field_result)
        
        return ExtractionResult(
            extraction_data=extraction_data,
            pages_processed=1,
            review_flags=review_flags,
            processing_time_ms=0,
            strategy_used="hybrid_consensus"
        )
    
    async def _process_with_openai(
        self,
        document_content: bytes,
        fields: List[FieldDefinition],
        prompt_general: str
    ) -> Dict[str, Any]:
        """Procesar documento con Azure OpenAI GPT-4 Vision"""
        logger.info("ü§ñ Procesando con Azure OpenAI GPT-4 Vision")
        
        try:
            # Convertir documento a base64
            document_b64 = base64.b64encode(document_content).decode('utf-8')
            
            # Construir prompt espec√≠fico
            fields_description = self._build_fields_description(fields)
            full_prompt = f"{prompt_general}\n\n{fields_description}"
            
            # Llamar a OpenAI
            response = await self.openai_client.process_document_vision(
                document_b64=document_b64,
                prompt=full_prompt,
                fields=fields
            )
            
            logger.info("‚úÖ Procesamiento con OpenAI completado exitosamente")
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Error en procesamiento OpenAI: {str(e)}")
            raise
    
    async def _process_with_openai_cascade(
        self,
        document_content: bytes,
        fields: List[FieldDefinition],
        prompt_general: str
    ) -> Dict[str, Any]:
        """Procesar documento con Azure OpenAI GPT-4 Vision usando estrategia cascada para mantener contexto"""
        logger.info("üîÑ Iniciando procesamiento GPT-4 Vision con estrategia cascada")
        logger.info(f"   üìä Tama√±o del documento: {len(document_content)} bytes")
        logger.info(f"   üîç Primeros bytes: {document_content[:10]}")
        
        try:
            # Importar convertidores inteligentes
            logger.info("   üì¶ Importando convertidores...")
            from app.utils.document_converter import DocumentConverter
            from app.utils.office_converter import OfficeConverter
            logger.info("   ‚úÖ Convertidores importados correctamente")
            
            # Determinar tipo de archivo y usar conversor apropiado
            logger.info("üîç Determinando tipo de archivo para conversi√≥n...")
            
            # Intentar detectar tipo por contenido (m√©todo simple)
            if document_content.startswith(b'%PDF'):
                # Es un PDF
                logger.info("üìÑ Archivo detectado como PDF, usando DocumentConverter")
                converter = DocumentConverter()
                images = converter.pdf_to_images_png(document_content)
            elif document_content.startswith(b'PK'):
                # Es un archivo Office (ZIP)
                logger.info("üìä Archivo detectado como Office (ZIP), usando OfficeConverter")
                converter = OfficeConverter()
                images = converter.office_to_images_png(document_content)
            else:
                # Intentar con OfficeConverter por defecto (m√°s vers√°til)
                logger.info("üîç Tipo no detectado, intentando con OfficeConverter")
                logger.info(f"   üîç Bytes de inicio: {document_content[:20]}")
                converter = OfficeConverter()
                images = converter.office_to_images_png(document_content)
            
            logger.info(f"üîÑ Convertidas {len(images)} p√°ginas del documento a im√°genes")
            
            if len(images) <= 5:
                # Una sola petici√≥n para documentos peque√±os
                logger.info(f"üìÑ Documento peque√±o ({len(images)} p√°ginas), procesando en una petici√≥n")
                return await self._process_single_batch(images, fields, prompt_general)
            else:
                # Procesamiento cascada para documentos grandes
                logger.info(f"üìö Documento grande ({len(images)} p√°ginas), procesando en cascada")
                return await self._process_cascade_batches(images, fields, prompt_general)
                
        except Exception as e:
            logger.error(f"‚ùå Error en procesamiento cascada: {str(e)}")
            raise
    
    async def _process_single_batch(
        self,
        images: List[str],
        fields: List[FieldDefinition],
        prompt_general: str
    ) -> Dict[str, Any]:
        """Procesar un lote de im√°genes en una sola petici√≥n"""
        logger.info(f"üìÑ Procesando {len(images)} im√°genes en una sola petici√≥n")
        
        try:
            # Verificar si las im√°genes ya est√°n en base64 o son rutas de archivo
            logger.info(f"   üîç Verificando formato de las im√°genes...")
            logger.info(f"   üìä Primera imagen (primeros 50 chars): {images[0][:50] if images else 'No hay im√°genes'}")
            
            # Las im√°genes del OfficeConverter ya est√°n en base64
            if images and images[0].startswith('data:image') or len(images[0]) > 1000:
                # Ya est√°n en base64, usar directamente
                logger.info(f"   ‚úÖ Im√°genes ya est√°n en base64, usando directamente")
                images_b64 = images
            else:
                # Convertir a base64 si son rutas de archivo
                logger.info(f"   üîÑ Convirtiendo rutas de archivo a base64...")
                images_b64 = []
                for img_path in images:
                    try:
                        with open(img_path, 'rb') as img_file:
                            img_data = img_file.read()
                            img_b64 = base64.b64encode(img_data).decode('utf-8')
                            images_b64.append(img_b64)
                    except Exception as img_error:
                        logger.warning(f"   ‚ö†Ô∏è Error convirtiendo imagen {img_path}: {str(img_error)}")
                        continue
            
            if not images_b64:
                raise Exception("No se pudieron procesar las im√°genes")
            
            logger.info(f"   ‚úÖ {len(images_b64)} im√°genes preparadas para GPT-4o")
            
            # Construir prompt espec√≠fico
            fields_description = self._build_fields_description(fields)
            full_prompt = f"{prompt_general}\n\n{fields_description}"
            
            # Llamar a OpenAI con TODAS las im√°genes del lote
            logger.info(f"   üñºÔ∏è Enviando {len(images_b64)} im√°genes a GPT-4o para an√°lisis conjunto")
            
            # Crear prompt mejorado para m√∫ltiples p√°ginas
            enhanced_prompt = f"""
            {full_prompt}
            
            üìÑ INSTRUCCIONES ESPECIALES PARA M√öLTIPLES P√ÅGINAS:
            - Est√°s analizando {len(images_b64)} p√°ginas del mismo documento
            - Cada p√°gina puede contener informaci√≥n diferente
            - Combina y consolida la informaci√≥n de TODAS las p√°ginas
            - Si un campo aparece en m√∫ltiples p√°ginas, usa la informaci√≥n m√°s completa
            - NO devuelvas null a menos que el campo no aparezca en NINGUNA p√°gina
            - Busca informaci√≥n complementaria entre las p√°ginas
            - Analiza cada imagen secuencialmente para construir una respuesta completa
            """
            
            # Enviar TODAS las im√°genes del lote a GPT-4o
            response = await self.openai_client.process_multiple_images_vision(
                images_b64=images_b64,
                prompt=enhanced_prompt,
                fields=fields
            )
            
            # Agregar informaci√≥n de que se analizaron m√∫ltiples p√°ginas
            response['multi_page_analysis'] = True
            response['total_pages_analyzed'] = len(images_b64)
            
            # Agregar informaci√≥n de p√°ginas procesadas
            response['pages_processed'] = len(images)
            
            logger.info(f"‚úÖ Procesamiento de lote √∫nico completado: {len(images)} p√°ginas")
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Error en procesamiento de lote √∫nico: {str(e)}")
            raise
    
    async def _process_cascade_batches(
        self,
        images: List[str],
        fields: List[FieldDefinition],
        prompt_general: str
    ) -> Dict[str, Any]:
        """Procesar im√°genes en lotes usando estrategia cascada para mantener contexto"""
        logger.info(f"üîÑ Iniciando procesamiento cascada para {len(images)} im√°genes")
        
        try:
            # Procesar primer lote (base)
            logger.info("üîÑ Procesando lote base (p√°ginas 1-5)")
            base_extraction = await self._process_single_batch(images[0:5], fields, prompt_general)
            
            # Procesar lotes subsiguientes con referencia al anterior
            for batch_idx in range(5, len(images), 5):
                batch = images[batch_idx:batch_idx + 5]
                current_pages = f"{batch_idx+1}-{min(batch_idx+5, len(images))}"
                
                logger.info(f"üîÑ Procesando lote {batch_idx//5 + 2} (p√°ginas {current_pages})")
                
                # Prompt que referencia la extracci√≥n anterior
                reference_prompt = f"""
                {prompt_general}
                
                üîÑ INFORMACI√ìN EXTRA√çDA ANTERIORMENTE:
                {self._format_extraction_for_prompt(base_extraction)}
                
                üìÑ INSTRUCCIONES ESPECIALES:
                - Complementa la informaci√≥n anterior con datos de las p√°ginas {current_pages}
                - Si hay contradicciones, prioriza la informaci√≥n m√°s reciente
                - Mant√©n la coherencia con los datos ya extra√≠dos
                - Agrega nuevos campos si los encuentras
                """
                
                batch_extraction = await self._process_single_batch(batch, fields, reference_prompt)
                base_extraction = self._merge_extractions(base_extraction, batch_extraction)
                
                logger.info(f"‚úÖ Lote {batch_idx//5 + 2} procesado y consolidado")
            
            # Agregar informaci√≥n de p√°ginas procesadas
            base_extraction['pages_processed'] = len(images)
            
            logger.info(f"‚úÖ Procesamiento cascada completado: {len(images)} p√°ginas procesadas")
            return base_extraction
                
        except Exception as e:
            logger.error(f"‚ùå Error en procesamiento cascada: {str(e)}")
            raise
    
    def _format_extraction_for_prompt(self, extraction: Dict[str, Any]) -> str:
        """Formatear extracci√≥n para incluir en prompt de referencia"""
        try:
            formatted = []
            for key, value in extraction.items():
                if key not in ['pages_processed', '_rid', '_etag', '_ts'] and value is not None:
                    formatted.append(f"- {key}: {value}")
            return "\n".join(formatted)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Error formateando extracci√≥n para prompt: {str(e)}")
            return "Informaci√≥n anterior no disponible"
    
    def _merge_extractions(self, base: Dict[str, Any], new: Dict[str, Any]) -> Dict[str, Any]:
        """Combinar extracciones manteniendo coherencia"""
        try:
            merged = base.copy()
            
            for key, value in new.items():
                if key in ['pages_processed', '_rid', '_etag', '_ts']:
                    continue
                    
                if key in merged:
                    # Si el campo ya existe, usar el valor m√°s reciente si no es None
                    if value is not None:
                        merged[key] = value
                else:
                    # Nuevo campo
                    merged[key] = value
            
            logger.info(f"üîÑ Extracciones combinadas: {len(merged)} campos totales")
            return merged
            
        except Exception as e:
            logger.error(f"‚ùå Error combinando extracciones: {str(e)}")
            return base
    
    async def _process_with_document_intelligence(
        self,
        document_content: bytes,
        fields: List[FieldDefinition],
        prompt_general: str
    ) -> Dict[str, Any]:
        """Procesar documento con Azure Document Intelligence"""
        logger.info("üìÑ Procesando con Azure Document Intelligence")
        
        try:
            # Llamar a Document Intelligence
            response = await self.doc_intelligence_client.process_document(
                document_content=document_content,
                fields=fields,
                prompt_general=prompt_general
            )
            
            logger.info("‚úÖ Procesamiento con Document Intelligence completado exitosamente")
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Error en procesamiento Document Intelligence: {str(e)}")
            raise
    
    def _build_fields_description(self, fields: List[FieldDefinition]) -> str:
        """Construir descripci√≥n de campos para el prompt"""
        fields_desc = "Campos a extraer:\n"
        for field in fields:
            fields_desc += f"- {field.name} ({field.type}): {field.description}\n"
        return fields_desc
    
    def _get_field_value(self, result: Dict[str, Any], field_name: str) -> Any:
        """Obtener valor de un campo espec√≠fico del resultado"""
        try:
            return result.get(field_name)
        except (KeyError, AttributeError):
            return None
    
    def _create_consensus_field(
        self,
        field_name: str,
        openai_value: Any,
        doc_intelligence_value: Any,
        field_definition: FieldDefinition
    ) -> ExtractionField:
        """Crear campo con consenso entre servicios"""
        
        # Determinar valor final y confianza
        if openai_value is not None and doc_intelligence_value is not None:
            if openai_value == doc_intelligence_value:
                final_value = openai_value
                confidence = 0.95
                review_required = False
            else:
                # Discrepancia - usar OpenAI como autoridad
                final_value = openai_value
                confidence = 0.8
                review_required = True
        elif openai_value is not None:
            final_value = openai_value
            confidence = 0.85
            review_required = False
        elif doc_intelligence_value is not None:
            final_value = doc_intelligence_value
            confidence = 0.75
            review_required = False
        else:
            final_value = None
            confidence = 0.0
            review_required = True
        
        return ExtractionField(
            name=field_name,
            value=final_value,
            confidence=confidence,
            review_required=review_required,
            source_strategy="dual_service",
            extraction_time_ms=0
        )

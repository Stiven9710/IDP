#!/usr/bin/env python3
"""
Script de prueba para el sistema IDP Expert System usando JSON de ejemplo
"""

import asyncio
import json
import logging
import os
from datetime import datetime

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_idp_with_json():
    """Probar el sistema IDP usando el JSON de ejemplo"""
    
    logger.info("ğŸ§ª Iniciando pruebas del sistema IDP con JSON de ejemplo")
    
    # Leer el JSON de ejemplo
    json_file_path = "test_request_example.json"
    
    if not os.path.exists(json_file_path):
        logger.error(f"âŒ No se encontrÃ³ el archivo: {json_file_path}")
        return
    
    try:
        with open(json_file_path, 'r', encoding='utf-8') as file:
            test_request = json.load(file)
        
        logger.info(f"âœ… JSON leÃ­do exitosamente desde: {json_file_path}")
        
    except json.JSONDecodeError as e:
        logger.error(f"âŒ Error parseando JSON: {str(e)}")
        return
    except Exception as e:
        logger.error(f"âŒ Error leyendo archivo: {str(e)}")
        return
    
    # Mostrar el request cargado
    logger.info("\nğŸ“‹ Request cargado desde JSON:")
    logger.info(f"   ğŸ“„ Documento: {test_request['document_path']}")
    logger.info(f"   ğŸ¯ Modo: {test_request['processing_mode']}")
    logger.info(f"   ğŸ“ Campos: {len(test_request['fields'])}")
    logger.info(f"   ğŸ†” Correlation ID: {test_request['metadata']['correlation_id']}")
    
    # Mostrar los campos definidos
    logger.info("\nğŸ“ Campos definidos para extracciÃ³n:")
    for i, field in enumerate(test_request['fields'], 1):
        logger.info(f"   {i:2d}. {field['name']} ({field['type']})")
        logger.info(f"       {field['description'][:80]}...")
    
    # Simular procesamiento segÃºn el tamaÃ±o del documento
    logger.info("\nğŸ” Simulando procesamiento del documento:")
    
    # El documento Invoice_2082463105.pdf es de 92KB (0.09 MB)
    file_size_mb = 0.09
    
    if file_size_mb <= 10.0:
        logger.info("âš¡ Procesamiento SÃNCRONO (archivo pequeÃ±o)")
        logger.info(f"   - TamaÃ±o del documento: {file_size_mb:.2f} MB")
        logger.info("   - El documento se procesa inmediatamente")
        logger.info("   - Se devuelve el resultado completo")
        logger.info("   - Tiempo de respuesta estimado: < 30 segundos")
        
        # Simular resultado sÃ­ncrono
        await simulate_sync_processing(test_request)
        
    else:
        logger.info("ğŸ”„ Procesamiento ASÃNCRONO (archivo grande)")
        logger.info(f"   - TamaÃ±o del documento: {file_size_mb:.2f} MB")
        logger.info("   - El documento se guarda en Blob Storage")
        logger.info("   - Se encola para procesamiento en segundo plano")
        logger.info("   - Se devuelve HTTP 202 + Job ID")
        logger.info("   - El cliente puede consultar el estado")
        
        # Simular resultado asÃ­ncrono
        await simulate_async_processing(test_request)


async def simulate_sync_processing(request: dict):
    """Simular procesamiento sÃ­ncrono"""
    logger.info("\nâš¡ Simulando procesamiento SÃNCRONO...")
    
    # Simular tiempo de procesamiento
    await asyncio.sleep(2)
    
    # Simular resultado de extracciÃ³n
    extraction_result = {
        "job_id": "sync-job-12345",
        "extraction_data": [
            {
                "name": "numero_factura",
                "value": "2082463105",
                "confidence": 0.95,
                "review_required": False,
                "source_strategy": "hybrid_consensus",
                "extraction_time_ms": 1500
            },
            {
                "name": "fecha_factura",
                "value": "2025-01-12",
                "confidence": 0.98,
                "review_required": False,
                "source_strategy": "hybrid_consensus",
                "extraction_time_ms": 1200
            },
            {
                "name": "total_a_pagar",
                "value": 150000.00,
                "confidence": 0.92,
                "review_required": False,
                "source_strategy": "hybrid_consensus",
                "extraction_time_ms": 1800
            }
        ],
        "processing_summary": {
            "processing_status": "completed",
            "processing_time_ms": 4500,
            "file_size_mb": 0.09,
            "strategy_used": "hybrid_consensus",
            "timestamp": datetime.utcnow().isoformat(),
            "pages_processed": 1,
            "review_flags": []
        },
        "message": "Documento procesado exitosamente de forma sÃ­ncrona",
        "correlation_id": request['metadata']['correlation_id']
    }
    
    logger.info("âœ… Resultado del procesamiento sÃ­ncrono:")
    logger.info(f"   ğŸ†” Job ID: {extraction_result['job_id']}")
    logger.info(f"   â±ï¸  Tiempo: {extraction_result['processing_summary']['processing_time_ms']}ms")
    logger.info(f"   ğŸ“Š Campos extraÃ­dos: {len(extraction_result['extraction_data'])}")
    logger.info(f"   ğŸ¯ Estrategia: {extraction_result['processing_summary']['strategy_used']}")
    
    # Mostrar campos extraÃ­dos
    for field in extraction_result['extraction_data']:
        logger.info(f"   ğŸ“ {field['name']}: {field['value']} (confianza: {field['confidence']})")


async def simulate_async_processing(request: dict):
    """Simular procesamiento asÃ­ncrono"""
    logger.info("\nğŸ”„ Simulando procesamiento ASÃNCRONO...")
    
    # Simular aceptaciÃ³n del trabajo
    job_id = "async-job-67890"
    
    logger.info(f"âœ… Trabajo aceptado para procesamiento asÃ­ncrono:")
    logger.info(f"   ğŸ†” Job ID: {job_id}")
    logger.info(f"   ğŸ“„ Documento: {request['document_path']}")
    logger.info(f"   ğŸ¯ Modo: {request['processing_mode']}")
    logger.info(f"   ğŸ“ Campos a extraer: {len(request['fields'])}")
    
    # Simular consulta de estado
    logger.info("\nğŸ” Simulando consulta de estado...")
    await asyncio.sleep(1)
    
    status_response = {
        "job_id": job_id,
        "status": "processing",
        "progress_percentage": 45.0,
        "current_step": "Procesando con Azure OpenAI",
        "message": "Documento en procesamiento"
    }
    
    logger.info(f"ğŸ“Š Estado del trabajo:")
    logger.info(f"   ğŸ“ˆ Progreso: {status_response['progress_percentage']}%")
    logger.info(f"   ğŸ”„ Paso actual: {status_response['current_step']}")
    logger.info(f"   ğŸ“ Mensaje: {status_response['message']}")


def show_api_usage():
    """Mostrar cÃ³mo usar la API"""
    
    logger.info("\nğŸŒ CÃ³mo usar la API IDP:")
    logger.info("=" * 50)
    
    logger.info("\n1ï¸âƒ£ Iniciar el servidor:")
    logger.info("   python main.py")
    
    logger.info("\n2ï¸âƒ£ Abrir la documentaciÃ³n interactiva:")
    logger.info("   http://159.203.149.247:8000/docs")
    
    logger.info("\n3ï¸âƒ£ Usar el endpoint principal:")
    logger.info("   POST /api/v1/documents/process")
    
    logger.info("\n4ï¸âƒ£ Copiar el JSON de ejemplo:")
    logger.info("   test_request_example.json")
    
    logger.info("\n5ï¸âƒ£ Endpoints adicionales disponibles:")
    logger.info("   GET  /api/v1/documents/{job_id}/status")
    logger.info("   GET  /api/v1/documents/{job_id}/result")
    logger.info("   GET  /api/v1/documents/search")
    logger.info("   GET  /api/v1/health")
    logger.info("   GET  /api/v1/jobs")
    
    logger.info("\n6ï¸âƒ£ Para pruebas con documentos reales:")
    logger.info("   - Reemplaza la URL en el JSON")
    logger.info("   - Ajusta los campos segÃºn el tipo de documento")
    logger.info("   - Cambia el modo de procesamiento segÃºn necesites")


def validate_json_structure():
    """Validar la estructura del JSON de ejemplo"""
    
    logger.info("\nğŸ” Validando estructura del JSON de ejemplo...")
    
    required_fields = ["document_path", "processing_mode", "prompt_general", "fields", "metadata"]
    required_field_properties = ["name", "type", "description"]
    
    try:
        with open("test_request_example.json", 'r', encoding='utf-8') as file:
            data = json.load(file)
        
        # Validar campos requeridos
        missing_fields = [field for field in required_fields if field not in data]
        if missing_fields:
            logger.error(f"âŒ Campos faltantes: {missing_fields}")
            return False
        
        # Validar estructura de fields
        if not isinstance(data['fields'], list):
            logger.error("âŒ 'fields' debe ser una lista")
            return False
        
        # Validar cada field
        for i, field in enumerate(data['fields']):
            missing_props = [prop for prop in required_field_properties if prop not in field]
            if missing_props:
                logger.error(f"âŒ Field {i}: propiedades faltantes: {missing_props}")
                return False
        
        logger.info("âœ… Estructura del JSON vÃ¡lida")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Error validando JSON: {str(e)}")
        return False


if __name__ == "__main__":
    logger.info("ğŸš€ IDP Expert System - Pruebas con JSON")
    logger.info("=" * 50)
    
    # Validar estructura del JSON
    if not validate_json_structure():
        logger.error("âŒ El JSON de ejemplo no es vÃ¡lido")
        exit(1)
    
    # Ejecutar pruebas
    asyncio.run(test_idp_with_json())
    
    # Mostrar uso de la API
    show_api_usage()
    
    logger.info("\nâœ¨ Â¡El sistema IDP estÃ¡ listo para procesar documentos reales!")
    logger.info("ğŸ“„ Usa el JSON de ejemplo como base para tus requests")
